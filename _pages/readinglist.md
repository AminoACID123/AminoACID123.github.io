---
layout: archive
title: "Reading List"
permalink: /readinglist/
author_profile: true
---

This page contains papers relevant to my research interest.

#All Papers(Classification according to Publication)

- **ISSTA**  
  - [A Large-Scale Empirical Analysis of the Vulnerabilities Introduced by Third-Party Components in IoT Firmware](#a-large-scale-empirical-analysis-of-the-vulnerabilities-introduced-by-third-party-components-in-iot-firmware-issta-2022)
  - [An Empirical Study on the Effectiveness of Static C Code Analyzers for Vulnerability Detection](#an-empirical-study-on-the-effectiveness-of-static-c-code-analyzers-for-vulnerability-detection-issta-2022)
  - [BET: Black-Box Efficient Testing for Convolutional Neural Networks (2022)](#bet-black-box-efficient-testing-for-convolutional-neural-networks-issta-2022)
  - [Detecting Multi-sensor Fusion Errors in Advanced Driver-Assistance Systems (2022)](#detecting-multi-sensor-fusion-errors-in-advanced-driver-assistance-systems-issta-2022)
  - [Efficient greybox fuzzing of applications in Linux-based IoT devices via enhanced user-mode emulation (2022)](#efficient-greybox-fuzzing-of-applications-in-linux-based-iot-devices-via-enhanced-user-mode-emulation-issta-2022)
  - LiRTest: augmenting LiDAR point clouds for automated testing of autonomous driving systems
  - [Binary Code Is Not Easy](#binary-code-is-not-easy)
  - [Reinforcement Learning Based Curiosity-Driven Testing of Android Application](#reinforcement-learning-based-curiosity-driven-testing-of-android-application)

- **PLDI**
  - [Context Sensitivity without Contexts](#context-sensitivity-without-contexts)
  - Finding typing compiler bugs
  - Odin: On-Demand Instrumentation with On-the-Fly Recompilation

- **ESEC/FSE**
  - Fuzzing Deep-Learning Libraries via Automated Relational API Inference
  - Generating Realistic Vulnerabilities via Neural Code Editing: An Empirical Study
  - MOSAT: Finding Safety Violations of Autonomous Driving Systems Using Multi-Objective Genetic Algorithm
  - Scenario-based Test Reduction and Prioritization for Multi-Module Autonomous Driving Systems
  - Static Executes-Before Analysis for Event Driven Programs
  - Understanding Performance Problems in Deep Learning Systems
  - Fuzzing Deep-Learning Libraries via Automated Relational API Inference
  - [Guided, Stochastic Model-Based GUI Testing of Android Apps](#guided-stochastic-model-based-gui-testing-of-android-apps)
  
- **TSE**
  - [Deep Reinforcement Learning for Black-box Testing of Android Apps](#deep-reinforcement-learning-for-black-box-testing-of-android-apps)

- **JAIR**
  - [DESPOT: Online POMDP Planning with Regularization](#despot-online-pomdp-planning-with-regularization)

- **ASE**  
  - B-AIS: An Automated Process for Black-box Evaluation of AI-enabled Software Systems against Domain Semantics
  - Boosting the Revealing of Detected Violations in Deep Learning Testing: A Diversity-Guided Method
  - LawBreaker: An Approach for Specifying Traffic Laws and Fuzzing Autonomous Vehicles
  - ThirdEye: Attention Maps for Safe Autonomous Driving Systems
  - Unveiling the Hidden Defection of DNN Testing with Decision-Based Metamorphic Oracle
  - [FIRMGUIDE: Boosting the Capability of Rehosting Embedded Linux Kernels through Model-Guided Kernel Execution](#firmguide-boosting-the-capability-of-rehosting-embedded-linux-kernels-through-model-guided-kernel-execution)
  - [Sorry, I don't understand: Improving Voice User Interface Testing](#sorry-i-dont-understand-improving-voice-user-interface-testing-ase-2022)
  - [Fastbot2: Reusable Automated Model-based GUI Testing for Android Enhanced by Reinforcement Learn](#fastbot2-reusable-automated-model-based-gui-testing-for-android-enhanced-by-reinforcement-learn)

- **ICSE**
  - Adaptive Test Selection for Deep Neural Networks
  - A Grounded Theory Based Approach to Characterize Software Attack Surfaces
  - BeDivFuzz: Integrating Behavioral Diversity into Generator-based Fuzzing
  - DeepState: Selecting Test Suites to Enhance the Robustness of Recurrent Neural Networks
  - Demystifying the Dependency Challenge in Kernel Fuzzing
  - EAGLE: Creating Equivalent Graphs to Test Deep Learning
  - Evaluating and Improving Neural Program-Smoothing-based Fuzzing
  - Large-scale Security Measurements on the Android Firmware Ecosystem
  - Linear-time Temporal Logic guided Greybox Fuzzing
  - Muffin: Testing Deep Learning Libraries via Neural Architecture Fuzzing
  - MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks
  - Nessie: Automatically Testing JavaScript APIs with Asynchronous Callbacks
  - PerfSig: Extracting Performance Bug Signatures via Multi-modality Causal Analysis
  - [Testing File System Implementations on Layered Models](#testing-file-system-implementations-on-layered-models)

- **OOPSLA**  
  - Coverage-guided tensor compiler fuzzing with joint IR-pass mutation  
  - [BDA: Practical Dependence Analysis for Binary Executables by Unbiased Whole-Program Path Sampling and Per-Path Abstract Interpretation (2019)](#bda-practical-dependence-analysis-for-binary-executables-by-unbiased-whole-program-path-sampling-and-per-path-abstract-interpretation)

- **S&P**
  - [SoK: All You Ever Wanted to Know About x86/x64 Binary Disassembly But Were Afraid to Ask](#sok-all-you-ever-wanted-to-know-about-x86x64-binary-disassembly-but-were-afraid-to-ask)
  - [Compiler-assisted Code Randomization]
  - [Recovery of Variable and Data Structure via Probabilistic Analysis for Stripped Binary](#recovery-of-variable-and-data-structure-via-probabilistic-analysis-for-stripped-binary)
  - [KARONTE: Detecting Insecure Multi-binary Interactions in Embedded Firmware (2020)](#karonte-detecting-insecure-multi-binary-interactions-in-embedded-firmware-sp-sp-2020)
  - [All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution (2010)]
  - [Back in Black: Towards Formal, Black Box Analysis of Sanitizers and Filters](#back-in-black-towards-formal-black-box-analysis-of-sanitizers-and-filters)
  - [Prospex: Protocol Specification Extraction](#prospex-protocol-specification-extraction)

- **NDSS**
  - [From Library Portability to Para-rehosting: Natively Executing Microcontroller Software on Commodity Hardware](#from-library-portability-to-para-rehosting-natively-executing-microcontroller-software-on-commodity-hardware)
  - [VulHawk: Cross-architecture Vulnerability Detection with Entropy-based Binary Code Search](#vulhawk-cross-architecture-vulnerability-detection-with-entropy-based-binary-code-search)
  - [Refining Indirect Call Targets at the Binary Level](#refining-indirect-call-targets-at-the-binary-level)

- **USENIX SEC**
  - [BLEEM: Packet Sequence Oriented Fuzzing for Protocol Implementations](#bleem-packet-sequence-oriented-fuzzing-for-protocol-implementations)
  - [UNIFUZZ: A Holistic and Pragmatic Metrics-Driven Platform for Evaluating Fuzzers (2022)](#unifuzz-a-holistic-and-pragmatic-metrics-driven-platform-for-evaluating-fuzzers)
  - [Arbiter: Bridging the Static and Dynamic Divide in Vulnerability Discovery on Binary Programs (2022)](#arbiter-bridging-the-static-and-dynamic-divide-in-vulnerability-discovery-on-binary-programs)
  - [Automatic Firmware Emulation through Invalidity-guided Knowledge Inference (2021)](#automatic-firmware-emulation-through-invalidity-guided-knowledge-inference)
  - [EcoFuzz: Adaptive Energy-Saving Greybox Fuzzing as a Variant of the Adversarial Multi-Armed Bandit]
  - [Selectivetaint: Efficient Data Flow Tracking With Static Binary Rewriting](#selectivetaint-efficient-data-flow-tracking-with-static-binary-rewriting)
  - [Sharing More and Checking Less: Leveraging Common Input Keywords to Detect Bugs in Embedded Systems](#sharing-more-and-checking-less-leveraging-common-input-keywords-to-detect-bugs-in-embedded-systems)
  - [FIRM-AFL: High-Throughput Greybox Fuzzing of IoT Firmware via Augmented Process Emulation (2019)](#firm-afl-high-throughput-greybox-fuzzing-of-iot-firmware-via-augmented-process-emulation)

- **USENIX ATC**
  - [TCP-Fuzz: Detecting Memory and Semantic Bugs in TCP Stacks with Fuzzing (2021)](#tcp-fuzz-detecting-memory-and-semantic-bugs-in-tcp-stacks-with-fuzzing)
  - [SweynTooth: Unleashing Mayhem over Bluetooth Low Energy (2020)]

- **SANER**
  - [RIBDetector: an RFC-guided Inconsistency Bug Detecting Approach for Protocol Implementations](#ribdetector-an-rfc-guided-inconsistency-bug-detecting-approach-for-protocol-implementations)

- **CCS**
  - [What Your Firmware Tells You Is Not How You Should Emulate It: A Speciﬁcation-Guided Approach for Firmware Emulation](#what-your-firmware-tells-you-is-not-how-you-should-emulate-it-a-speciﬁcation-guided-approach-for-firmware-emulation)
  - [MetaEmu: An Architecture Agnostic Rehosting Framework for Automotive Firmware](#metaemu-an-architecture-agnostic-rehosting-framework-for-automotive-firmware)
  - [ECMO: Peripheral Transplantation to Rehost Embedded Linux Kernels](#ecmo-peripheral-transplantation-to-rehost-embedded-linux-kernels-ccs-2021)
  - [SFADiff: Automated Evasion Attacks and Fingerprinting Using Black-box Differential Automata Learning](#sfadiff-automated-evasion-attacks-and-fingerprinting-using-black-box-differential-automata-learning)

- **DSN**
  - [L2Fuzz: Discovering Bluetooth L2CAP Vulnerabilities Using Stateful Fuzz Testing](#l2fuzz-discovering-bluetooth-l2cap-vulnerabilities-using-stateful-fuzz-testing-dsn-2022)

- **ACSAC**
  - [FirmAE: Towards Large-Scale Emulation of IoT Firmware for Dynamic Analysis (2020)](#firmae-towards-large-scale-emulation-of-iot-firmware-for-dynamic-analysis)

- **TOPLAS**
  - [WYSINWYX: What you see is not what you eXecute]



- **Computers & Security**
  - [VERI: A Large-scale Open-Source Components Vulnerability Detection in IoT Firmware](#veri-a-large-scale-open-source-components-vulnerability-detection-in-iot-firmware)
  
- **MISC**
  - [Automatic Vulnerability Detection in Embedded Devices and Firmware: Survey and Layered Taxonomies](#automatic-vulnerability-detection-in-embedded-devices-and-firmware-survey-and-layered-taxonomies)  
  - [Challenges in Firmware Re-Hosting, Emulation, and Analysis](#challenges-in-firmware-re-hosting-emulation-and-analysis)
  - [Systematic Testing of Autonomous Driving Systems Using Map Topology-Based Scenario Classification](#systematic-testing-of-autonomous-driving-systems-using-map-topology-based-scenario-classification)
  - [Fingerprinting Bluetooth Low Energy Devices via Active Automata Learning](#fingerprinting-bluetooth-low-energy-devices-via-active-automata-learning)
  - [Stateful Black-Box Fuzzing of Bluetooth Devices Using Automata Learning](#stateful-black-box-fuzzing-of-bluetooth-devices-using-automata-learning)
  - [Learning Regular Sets from Queries and Counterexamples](#learning-regular-sets-from-queries-and-counterexamples)
  - [Decompilation of Binaries into LLVM IR for Automated Analysis](#decompilation-of-binaries-into-llvm-ir-for-automated-analysis)
  - [Analyzing Memory Accesses in x86 Executables](#analyzing-memory-accesses-in-x86-executables)
  - [A Formal Semantics for P-Code]
  - [Generating models of infinite-state communication protocols using regular inference with abstraction](#generating-models-of-infinite-state-communication-protocols-using-regular-inference-with-abstraction)
  - [Challenges and Solutions for Embedded and Networked Aerospace Software Systems](#challenges-and-solutions-for-embedded-and-networked-aerospace-software-systems)
  - [Physical Devices-Agnostic Hybrid Fuzzing of IoT Firmware](#physical-devices-agnostic-hybrid-fuzzing-of-iot-firmware)
  - [Adaptive and Effective Fuzzing: A Data-Driven Approach](#adaptive-and-effective-fuzzing-a-data-driven-approach)
  - [Learning deterministic probabilistic automata from a model checking perspective](#learning-deterministic-probabilistic-automata-from-a-model-checking-perspective)




### A Large-Scale Empirical Analysis of the Vulnerabilities Introduced by Third-Party Components in IoT Firmware (ISSTA 2022)
* <img src="../files/images/pdf_24px.png">[Paper](/files/papers/A_large_scale_empirical_analysis_of_the_vulnerabilities_introduced_by_third_party_components_in_IOT_firmware.pdf)

* **Abstract:** As the core of IoT devices, firmware is undoubtedly vital. Currently, the development of IoT firmware heavily depends on third-party components (TPCs), which significantly improves the development efficiency and reduces the cost. Nevertheless, TPCs are not secure, and the vulnerabilities in TPCs will turn back influence the security of IoT firmware. Currently, existing works pay less attention to the vulnerabilities caused by TPCs, and we still lack a comprehensive understanding of the security impact of TPC vulnerability against firmware.  
To fill in the knowledge gap, we design and implement FirmSec, which leverages syntactical features and control-flow graph features to detect the TPCs at version-level in firmware, and then recognizes the corresponding vulnerabilities. Based on FirmSec, we present the first large-scale analysis of the usage of TPCs and the corresponding vulnerabilities in firmware. More specifically, we perform an analysis on 34, 136 firmware images, including 11, 086 publicly accessible firmware images, and 23, 050 private firmware images from TSmart. We successfully detect 584 TPCs and identify 128, 757 vulnerabilities caused by 429 CVEs. Our in-depth analysis reveals the diversity of security issues for different kinds of firmware from various vendors, and discovers some well-known vulnerabilities are still deeply rooted in many firmware images. We also find that the TPCs used in firmware have fallen behind by five years on average. Besides, we explore the geographical distribution of vulnerable devices, and confirm the security situation of devices in several regions, e .g., South Korea and China, is more severe than in other regions. Further analysis shows 2, 478 commercial firmware images have potentially violated GPL/AGPL licensing terms.

### An Empirical Study on the Effectiveness of Static C Code Analyzers for Vulnerability Detection (ISSTA 2022)
* <img src="../files/images/pdf_24px.png">[Paper](/files/papers/An_empirical_study_on_the_effectiveness_of_static_C_code_analyzers_for_vulnerability_detection.pdf)

* **Abstract:** Static code analysis is often used to scan source code for security vulnerabilities. Given the wide range of existing solutions implementing different analysis techniques, it is very challenging to perform an objective comparison between static analysis tools to determine which ones are most effective at detecting vulnerabilities. Existing studies are thereby limited in that (1) they use synthetic datasets, whose vulnerabilities do not reflect the complexity of security bugs that can be found in practice and/or (2) they do not provide differentiated analyses w.r.t. the types of vulnerabilities output by the static analyzers. Hence, their conclusions about an analyzer’s capability to detect vulnerabilities may not generalize to real-world programs. In this paper, we propose a methodology for automatically evaluating the effectiveness of static code analyzers based on CVE reports. We evaluate five free and open-source and one commercial static C code analyzer(s) against 27 software projects containing a total of 1.15 million lines of code and 192 vulnerabilities (ground truth). While static C analyzers have been shown to perform well in benchmarks with synthetic bugs, our results indicate that state-of-the-art tools miss in-between 47% and 80% of the vulnerabilities in a benchmark set of real-world programs. Moreover, our study finds that this false negative rate can be reduced to 30% to 69% when combining the results of static analyzers, at the cost of 15 percentage points more functions flagged. Many vulnerabilities hence remain undetected, especially those beyond the classical memory-related security bugs.  

### BET: Black-Box Efficient Testing for Convolutional Neural Networks (ISSTA 2022)
* <img src="../files/images/pdf_24px.png">[Paper](/files/papers/BET_black_box_efficient_testing_for_convolutional_neural_networks.pdf)

* **Abstract:** It is important to test convolutional neural networks (CNNs) to identify defects (e.g. error-inducing inputs) before deploying them in security-sensitive scenarios. Although existing white-box testing methods can effectively test CNN models with high neuron coverage, they are not applicable to privacy-sensitive scenarios where full knowledge of target CNN models is lacking. In this work, we propose a novel Black-box Efficient Testing (BET) method for CNN models. The core insight of BET is that CNNs are generally prone to be affected by continuous perturbations. Thus, by generating such continuous perturbations in a black-box manner, we design a tunable objective function to guide our testing process for thoroughly exploring defects in different decision boundaries of the target CNN models. We further design an efficiency-centric policy to find more error-inducing inputs within a fixed query budget. We conduct extensive evaluations with three well-known datasets and five popular CNN structures. The results show that BET significantly outperforms existing white-box and black-box testing methods considering the effective error-inducing inputs found in a fixed query/inference budget. We further show that the error-inducing inputs found by BET can be used to fine-tune the target model, improving its accuracy by up to 3%.

### Detecting Multi-sensor Fusion Errors in Advanced Driver-Assistance Systems (ISSTA 2022)
* <img src="../files/images/pdf_24px.png">[Paper](/files/papers/Detecting_multi_sensor_fusion_errors_in_advanced_driver_assistance_systems.pdf)
* <img src="../files/images/youdao_note_24px.png">[Reading Note](../files/notes/issta22Detecting.pdf)

* **Abstract:** Advanced Driver-Assistance Systems (ADAS) have been thriving and widely deployed in recent years. In general, these systems receive sensor data, compute driving decisions, and output control signals to the vehicles. To smooth out the uncertainties brought by sensor outputs, they usually leverage multi-sensor fusion (MSF) to fuse the sensor outputs and produce a more reliable understanding of the surroundings. However, MSF cannot completely eliminate the uncertainties since it lacks the knowledge about which sensor provides the most accurate data and how to optimally integrate the data provided by the sensors. As a result, critical consequences might happen unexpectedly. In this work, we observed that the popular MSF methods in an industry-grade ADAS can mislead the car control and result in serious safety hazards. We define the failures (e.g., car crashes) caused by the faulty MSF as fusion errors and develop a novel evolutionary-based domain-specific search framework, FusED, for the efficient detection of fusion errors. We further apply causality analysis to show that the found fusion errors are indeed caused by the MSF method. We evaluate our framework on two widely used MSF methods in two driving environments. Experimental results show that FusED identifies more than 150 fusion errors. Finally, we provide several suggestions to improve the MSF methods we study.

### Efficient greybox fuzzing of applications in Linux-based IoT devices via enhanced user-mode emulation (ISSTA 2022)
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Efficient_Greybox_Fuzzing_of_Applications_in_Linux_Based_IOT_Devices_via_Enhanced_User_Mode_Emulation.pdf)
* <img src="../files/images/youdao_note_24px.png">[Reading Note](../files/notes/issta22Efficient.pdf)

* **Abstract:** Greybox fuzzing has become one of the most effective vulnerability discovery techniques. However, greybox fuzzing techniques cannot be directly applied to applications in IoT devices. The main reason is that executing these applications highly relies on specific system environments and hardware. To execute the applications in Linux-based IoT devices, most existing fuzzing techniques use full-system emulation for the purpose of maximizing compatibility. However, compared with user-mode emulation, full-system emulation suffers from great overhead. Therefore, some previous works, such as FirmAFL, propose to combine full-system emulation and user-mode emulation to speed up the fuzzing process. Despite the attempts of trying to shift the application towards user-mode emulation, no existing technique supports to execute these applications fully in the user-mode emulation.  
To address this issue, we propose EQUAFL, which can automatically set up the execution environment to execute embedded applications under user-mode emulation. EQUAFL first executes the application under full-system emulation and observe for the key points where the program may get stuck or even crash during user-mode emulation. With the observed information, EQUAFL can migrate the needed environment for user-mode emulation. Then, EQUAFL uses an enhanced user-mode emulation to replay system calls of network, and resource management behaviors to fulfill the needs of the embedded application during its execution.  
We evaluate EQUAFL on 70 network applications from different series of IoT devices. The result shows EQUAFL outperforms the state-of-the-arts in fuzzing efficiency (on average, 26 times faster than AFL-QEMU with full-system emulation, 14 times than FirmAFL). We have also discovered ten vulnerabilities including six CVEs from the tested firmware images.

### What Your Firmware Tells You Is Not How You Should Emulate It: A Speciﬁcation-Guided Approach for Firmware Emulation
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/What_your_firmware_tells_you_is_not_how_you_should_emulate_it.pdf)

* **Abstract:** Emulating firmware of microcontrollers is challenging due to the lack of peripheral models. Existing work finds out how to respond to peripheral read operations by analyzing the target firmware. This is problematic because the firmware sometimes does not contain enough clues to support the emulation or even contains misleading information (e.g., a buggy firmware). In this work, we propose a new approach that builds peripheral models from the peripheral specification. Using NLP, we translate peripheral behaviors in human language (documented in chip manuals) into a set of structured condition-action rules. By checking, executing, and chaining them at runtime, we can dynamically synthesize a peripheral model for each firmware execution. The extracted condition-action rules might not be complete or even be wrong. We, therefore, propose incorporating symbolic execution to quickly pinpoint the root cause.  
This assists us in the manual correction of the problematic rules. We have implemented our idea for five popular MCU boards spanning three different chip vendors. Using a new edit-distance-based algorithm to calculate trace differences, our evaluation against a large firmware corpus confirmed that our prototype achieves much higher fidelity compared with state-of-the-art solutions. Benefiting from the accurate emulation, our emulator effectively avoids false positives observed in existing fuzzing work. We also designed a new dynamic analysis method to perform driver code compliance checks against the specification. We found some non-compliance which we later confirmed to be bugs caused by race conditions.

### Automatic Vulnerability Detection in Embedded Devices and Firmware: Survey and Layered Taxonomies
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Automatic_Vulnerability_Detection_in_Embedded_Devices_and_Firmware_Survey_and_Layered_Taxonomies.pdf)

* **Abstract:** In the era of the internet of things (IoT), software-enabled inter-connected devices are of paramount impor-
tance. The embedded systems are very frequently used in both security and privacy-sensitive applications. However, the underlying software (a.k.a. firmware) very often suffers from a wide range of security vulnerabilities, mainly due to their outdated systems or reusing existing vulnerable libraries; which is evident by the surprising rise in the number of attacks against embedded systems. Therefore, to protect those embedded systems, detecting the presence of vulnerabilities in the large pool of embedded devices and their firmware plays a vital role. To this end, there exist several approaches to identify and trigger potential vulnerabilities within deployed embedded systems firmware. In this survey, we provide a comprehensive review of the state-of-the-art proposals, which detect vulnerabilities in embedded systems and firmware images by employing various analysis techniques, including static analysis, dynamic analysis, symbolic execution, and hybrid approaches. Furthermore, we perform both quantitative and qualitative comparisons among the surveyed approaches. Moreover, we devise taxonomies based on the applications of those approaches, the features used in the literature, and the type of the analysis. Finally, we identify the unresolved challenges and discuss possible future directions in this field of research.

### Nessie: Automatically Testing JavaScript APIs with Asynchronous Callbacks
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Nessie_automatically_testing_JavaScript_APIs_with_asynchronous_callbacks.pdf)
* <img src="../files/images/youdao_note_24px.png">[Reading Note](../files/notes/icse22nessie.md)

* **Abstract:** Previous algorithms for feedback-directed unit test generation iteratively create sequences of API calls by executing partial tests and by adding new API calls at the end of the test. These algorithms are challenged by a popular class of APIs: higher-order functions that receive callback arguments, which often are invoked asynchronously. Existing test generators cannot effectively test such APIs because they only sequence API calls, but do not nest one call into the callback function of another. This paper presents Nessie, the first feedback-directed unit test generator that supports nesting of API calls and that tests asynchronous callbacks. Nesting API calls enables a test to use values produced by an API that are available only once a callback has been invoked, and is often necessary to ensure that methods are invoked in a specific order. The core contributions of our approach are a tree-based representation of unit tests with callbacks and a novel algorithm to iteratively generate such tests in a feedback-directed manner. We evaluate our approach on ten popular JavaScript libraries with both asynchronous and
synchronous callbacks. The results show that, in a comparison with LambdaTester, a state of the art test generation technique that only considers sequencing of method calls, Nessie finds more behavioral differences and achieves slightly higher coverage. Notably, Nessie needs to generate significantly fewer tests to achieve and exceed the coverage achieved by the state of the art.

### Challenges in Firmware Re-Hosting, Emulation, and Analysis
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Challenges_in_firmware_rehosting_emulation_and_analysis.pdf)

* **Abstract:** System emulation and firmware re-hosting have become popular techniques to answer various security and
performance related questions, such as determining whether a firmware contain security vulnerabilities or meet timing requirements when run on a specific hardware platform. While this motivation for emulation and binary analysis has previously been explored and reported, starting to either work or research in the field is difficult. To this end, we provide a comprehensive guide for the practitioner or system emulation researcher. We layout common challenges faced during firmware re-hosting, explaining successive steps and surveying common tools used to overcome these challenges. We provide classification techniques on five different axes,
including emulator methods, system type, fidelity, emulator purpose, and control. These classifications and comparison criteria enable the practitioner to determine the appropriate tool for emulation. We use our classifications to categorize popular works in the field and present 28 common challenges faced when creating, emulating, and analyzing a system from obtaining firmwares to post emulation analysis.

### Systematic Testing of Autonomous Driving Systems Using Map Topology-Based Scenario Classification
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Systematica_testing_of_autonomous_driving_systems_using_map_topology_based_scenario_classification.pdf)

* **Abstract:** Autonomous Driving Systems (ADSs), which replace humans to drive vehicles, are complex software systems deployed in autonomous vehicles (AVs). Since the execution of ADSs highly relies on maps, it is essential to perform global map-based testing for ADSs to guarantee their correctness and AVs’ safety in different situations. Existing methods focus more on specific
scenarios rather than global testing throughout the map. Testing on a global map is challenging since the complex lane connections in a map can generate enormous scenarios. In this work, we propose ATLAS, an approach to ADSs’ collision avoidance testing using map topology-based scenario classification. The core insight of ATLAS is to generate diverse testing scenarios by classifying junction lanes according to their topology-based interaction patterns. First, ATLAS divides the junction lanes into different classes such that an ADS can execute similar collision avoidance maneuvers on the lanes in the same class. Second, for each class, ATLAS selects one junction lane to construct the testing scenario and generate test cases using a genetic algorithm. Finally, we implement and evaluate ATLAS on Baidu Apollo with the LGSVL simulator on the San Francisco map. Results show that ATLAS exposes nine types of real issues in Apollo 6.0 and reduces the number of junction lanes for testing by 98%.

### FIRMGUIDE: Boosting the Capability of Rehosting Embedded Linux Kernels through Model-Guided Kernel Execution
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/FirmGuide.pdf)

* **Abstract:** Linux kernel is widely used in embedded systems.To understand practical threats to the Linux kernel, we need to perform dynamic analysis with a full-system emulator, e.g., QEMU. However, due to hardware fragmentation, e.g., various types of peripherals, most embedded systems are not currently supported by QEMU. Though some progress has been made on rehosting firmware, it mainly focuses on user space programs or simple real-time operating systems.   The goal of this work is to boost the capability of rehosting the embedded Linux kernels in QEMU. By doing so, dynamic analysis systems can be firstly applied on embedded Linux kernels by leveraging off-the-shelf tools upon QEMU. Accordingly, we proposed a new technique called model-guided kernel execution. It combines the peripheral abstractions in the Linux kernel and kernel-peripheral interactions to semi-automatically generate peripheral models that are then used to synthesize new QEMU virtual machines to start the dynamic analysis.   We have implemented a prototype called FirmGuide. It generates 9 peripheral models with full functionality and 64 with minimum functionality covering 26 SoCs. Our evaluation with 6, 188 firmware images shows that it can successfully rehost more than 95% of Linux kernels in 2 architectures and 22 versions. None of them can be rehosted in the vanilla QEMU. The result of the LTP benchmark shows the reliability and robustness of the rehosted Linux kernels. We further conduct two security applications, i.e., vulnerability analysis and fuzzing, on the rehosted Linux kernels to demonstrate the usage scenarios.


### From Library Portability to Para-rehosting: Natively Executing Microcontroller Software on Commodity Hardware
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/From_library_portibility_to_para_rehosting.pdf)

* **Abstract:** Finding bugs in microcontroller (MCU) firmware is challenging, even for device manufacturers who own the source code. The MCU runs different instruction sets than x86 and exposes a very different development environment. This invalidates many existing sophisticated software testing tools on x86. To maintain a unified developing and testing environment, a straightforward way is to re-compile the source code into the native executable for a commodity machine (called rehosting). However, ad-hoc re-hosting is a daunting and tedious task and subject to many issues (library-dependence, kernel-dependence and hardware-dependence). In this work, we systematically explore the portability problem of MCU software and propose pararehosting to ease the porting process. Specifically, we abstract and implement a portable MCU (PMCU) using the POSIX interface. It models common functions of the MCU cores. For peripheral specific logic, we propose HAL-based peripheral function replacement, in which high-level hardware functions are replaced with an equivalent backend driver on the host. These backend drivers are invoked by well-designed para-APIs and can be reused across many MCU OSs. We categorize common HAL functions into four types and implement templates for quick backend development. Using the proposed approach, we have successfully rehosted nine MCU OSs including the widely deployed Amazon FreeRTOS, ARM Mbed OS, Zephyr and LiteOS. To demonstrate the superiority of our approach in terms of security testing, we used off-the-shelf dynamic analysis tools (AFL and ASAN) against the rehosted programs and discovered 28 previously-unknown bugs, among which 5 were confirmed by CVE and the other 19 were confirmed by vendors at the time of writing.

### KARONTE: Detecting Insecure Multi-binary Interactions in Embedded Firmware (S&P S&P 2020)
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Karonte_Detecting_Insecure_Multi-binary_Interactions_in_Embedded_Firmware.pdf)

* **Abstract:** Low-power, single-purpose embedded devices (e.g., routers and IoT devices) have become ubiquitous. While they automate and simplify many aspects of users’ lives, recent large-scale attacks have shown that their sheer number poses a severe threat to the Internet infrastructure. Unfortunately, the software on these systems is hardware-dependent, and typically executes in unique, minimal environments with non-standard configurations, making security analysis particularly challenging. Many of the existing devices implement their functionality through the use of multiple binaries. This multi-binary service implementation renders current static and dynamic analysis techniques either ineffective or inefficient, as they are unable to identify and adequately model the communication between the various executables. In this paper, we present KARONTE, a static analysis approach capable of analyzing embedded-device firmware by modeling and tracking multi-binary interactions.  
Our approach propagates taint information between binaries to detect insecure interactions and identify vulnerabilities. We first evaluated KARONTE on 53 firmware samples from various vendors, showing that our prototype tool can successfully track and constrain multi-binary interactions. This led to the discovery of 46 zero-day bugs. Then, we performed a large-scale experiment on 899 different samples, showing that KARONTE scales well with firmware samples of different size and complexity.

### ECMO: Peripheral Transplantation to Rehost Embedded Linux Kernels (CCS 2021)
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/ecmo-ccs21.pdf)

* **Abstract:** Dynamic analysis based on the full-system emulator QEMU is widely used for various purposes. However, it is challenging to run firmware images of embedded devices in QEMU, especially the process to boot the Linux kernel (we call this process rehosting the Linux kernel in this paper). That’s because embedded devices usually use different system-on-chips (SoCs) from multiple vendors and only a limited number of SoCs are currently supported in QEMU.  
In this work, we propose a technique called peripheral transplantation. The main idea is to transplant the device drivers of
designated peripherals into the Linux kernel binary. By doing so, it can replace the peripherals in the kernel that are currently unsupported in QEMU with supported ones, thus making the Linux kernel rehostable. After that, various applications can be built.  
We implemented this technique inside a prototype system called ECMO and applied it to 815 firmware images, which consist of 20
kernel versions and 37 device models. The result shows that ECMO can successfully transplant peripherals for all the 815 Linux kernels. Among them, 710 kernels can be successfully rehosted, i.e., launching a user-space shell (87.1% success rate). The failed cases are mainly because the root file system format (ramfs) is not supported by the kernel. Meanwhile, we are able to inject rather complex drivers (i.e., NIC driver) for all the rehosted Linux kernels by installing kernel modules. We further build three applications, i.e., kernel crash analysis, rootkit forensic analysis, and kernel fuzzing, based on the rehosted kernels to demonstrate the usage scenarios of ECMO.

### MetaEmu: An Architecture Agnostic Rehosting Framework for Automotive Firmware (CCS 2022)
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/METAEMU.pdf)

* **Abstract:** In this paper we present MetaEmu, an architecture-agnostic emulator synthesizer geared towards rehosting and security analysis of automotive firmware. MetaEmu improves over existing rehosting environments in two ways: Firstly, it solves the hitherto openproblem of a lack of generic Virtual Execution Environments (VXEs) for rehosting by synthesizing processor simulators from Ghidra’s language definitions. In doing so, MetaEmu can simulate any processor supported by a vast and growing library of open-source definitions. In MetaEmu, we use a specification-based approach to cover peripherals, execution models, and analyses, which allows our framework to be easily extended. Secondly, MetaEmu can rehost and analyze multiple targets, each of different architecture, simultaneously, and share analysis facts between each target’s analysis environment, a technique we call inter-device analysis.  
We show that the flexibility afforded by our approach does not lead to a performance trade-off—MetaEmu lifts rehosted firmware to an optimized intermediate representation, and provides performance comparable to existing emulation tools, such as Unicorn. Our evaluation spans five different architectures, bare-metal and RTOS-based firmware, and three kinds of automotive Electronic
Control Unit (ECU) from four distinct vendors—none of which can be rehosted or emulated by current tools, due to lack of processor support. Further, we show how MetaEmu enables a diverse set of analyses by implementing a fuzzer, a symbolic executor for solving
peripheral access checks, a CAN ID reverse engineering tool, and an inter-device coverage tracker

### L2Fuzz: Discovering Bluetooth L2CAP Vulnerabilities Using Stateful Fuzz Testing (DSN 2022)
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/L2Fuzz_Discovering_Bluetooth_L2CAP_Vulnerabilities_Using_Stateful_Fuzz_Testing.pdf)

* **Abstract:** Bluetooth Basic Rate/Enhanced Data Rate (BR/EDR) is a wireless technology used in billions of devices. Recently, several Bluetooth fuzzing studies have been conducted to detect vulnerabilities in Bluetooth devices, but they fall short of effectively generating malformed packets. In this paper, we propose L2FUZZ, a stateful fuzzer to detect vulnerabilities in Bluetooth BR/EDR Logical Link Control and Adaptation Protocol (L2CAP) layer. By selecting valid commands for each state and mutating only the core fields of packets, L2FUZZ can generate valid malformed packets that are less likely to be rejected by the target device. Our experimental results confirmed that: (1) L2FUZZ generates up to 46 times more malformed packets with a much less packet rejection ratio compared to the existing techniques, and (2) L2FUZZ detected five zero-day vulnerabilities from eight real-world Bluetooth devices.

### Sorry, I don’t Understand: Improving Voice User Interface Testing (ASE 2022)
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/ASE2022VUI.pdf)

* **Abstract:** Voice-based virtual assistants are becoming increasingly popular. Such systems provide frameworks to developers on which they can build their own apps. End-users can interact with such apps through a Voice User Interface (VUI), which allows to use natural language commands to perform actions. Testing such apps is far from trivial: The same command can be expressed in different ways. To support developers in testing VUIs, Deep Learning (DL)-based tools have been integrated in the development environments (e.g., the Alexa Developer Console, or ADC) to generate paraphrases for the commands (seed utterances) specified by the developers. Such tools, however, generate few paraphrases that do not always cover corner cases. In this paper, we introduce VUIUPSET, a novel approach that aims at adapting chatbot-testing approaches to VUI-testing. Both systems, indeed, provide a similar
natural-language-based interface to users. We conducted an empirical study to understand how VUI-UPSET compares to existing approaches in terms of (i) correctness of the generated paraphrases, and (ii) capability of revealing bugs. Multiple authors analyzed 5,872 generated paraphrases, with a total of 13,310 manual evaluations required for such a process. Our results show that, while the DLbased tool integrated in the ADC generates a higher percentage of meaningful paraphrases compared to VUI-UPSET, VUI-UPSET generates more bug-revealing paraphrases. This allows developers to test more thoroughly their apps at the cost of discarding a higher number of irrelevant paraphrases.


### Fuzzing Deep-Learning Libraries via Automated Relational API Inference
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Fuzzing_deep_learning_libraries_via_automated_relational_api_inference.pdf)

* **Abstract:** Deep Learning (DL) has gained wide attention in recent years. Meanwhile, bugs in DL systems can lead to serious consequences, and may even threaten human lives. As a result, a growing body of research has been dedicated to DL model testing. However, there is still limited work on testing DL libraries, e.g., PyTorch and TensorFlow, which serve as the foundations for building, training, and running DL models. Prior work on fuzzing DL libraries can only generate tests for APIs which have been invoked by documentation examples, developer tests, or DL models, leaving a large number of APIs untested. In this paper, we propose DeepREL, the first approach to automatically inferring relational APIs for more effective DL library fuzzing. Our basic hypothesis is that for a DL library under test, there may exist a number of APIs sharing similar input parameters and outputs; in this way, we can easily “borrow” test inputs from invoked APIs to test other relational APIs. Furthermore, we formalize the notion of value equivalence and status equivalence for relational APIs to serve as the oracle for effective bug finding.  
We have implemented DeepREL as a fully automated end-to-end relational API inference and fuzzing technique for DL libraries, which
1) automatically infers potential API relations based on API syntactic/semantic information, 2) synthesizes concrete test programs for invoking relational APIs, 3) validates the inferred relational APIs via representative test inputs, and finally 4) performs fuzzing on the verified relational APIs to find potential inconsistencies. Our evaluation on two of the most popular DL libraries, PyTorch and TensorFlow, demonstrates that DeepREL can cover 157% more APIs than state-of-the-art FreeFuzz. To date, DeepREL has detected 162 bugs in total, with 106 already confirmed by the developers as previously unknown bugs. Surprisingly, DeepREL has detected 13.5% of the high-priority bugs for the entire PyTorch issue-tracking system in a three-month period. Also, besides the 162 code bugs, we have also detected 14 documentation bugs (all confirmed).

### Fingerprinting Bluetooth Low Energy Devices via Active Automata Learning

* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Fingerprinting_Bluetooth_Low_Energy_Devices_via_Active_Automata_Learning.pdf)

* **Abstract:** Active automata learning is a technique to automatically infer behavioral models of black-box systems. Today’s learning algorithms
enable the deduction of models that describe complex system properties, e.g., timed or stochastic behavior. Despite recent improvements in
the scalability of learning algorithms, their practical applicability is still
an open issue. Little work exists that actually learns models of physical black-box systems. To fill this gap in the literature, we present a
case study on applying automata learning on the Bluetooth Low Energy (BLE) protocol. It shows that not the size of the system limits
the applicability of automata learning. Instead, the interaction with the
system under learning, is a major bottleneck that is rarely discussed.
In this paper, we propose a general automata learning architecture for
learning a behavioral model of the BLE protocol implemented by a physical device. With this framework, we can successfully learn the behavior
of five investigated BLE devices. The learned models reveal several behavioral differences. This shows that automata learning can be used for
fingerprinting black-box devices, i.e., identifying systems via their specific learned models. Based on the fingerprint, an attacker may exploit
vulnerabilities specific to a device.

### Stateful Black-Box Fuzzing of Bluetooth Devices Using Automata Learning

* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/BLE_Automata.pdf)

* **Abstract:** Fuzzing (aka fuzz testing) shows promising results in security testing. The advantage of fuzzing is the relatively simple applicability compared to comprehensive manual security analysis. However, the eﬀectiveness of black-box fuzzing is hard to judge since the internal structure of the system under test is unknown. Hence, in-depth behavior might not be covered by fuzzing. This paper aims at overcoming the limitations of black-box fuzzing. We present a stateful black-box fuzzing technique that uses a behavioral model of the system under test. Instead of manually creating the model, we apply active automata learning to automatically infer the model. Our framework generates a test suite for fuzzing that includes valid and invalid inputs. The goal is to explore unexpected behavior. For this, we test for conformance between the learned model and the system under test. Additionally, we analyze behavioral diﬀerences using the learned state information. In a case study, we evaluate implementations of the Bluetooth Low Energy (BLE) protocol on physical devices. The results reveal security and dependability issues in the tested devices leading to crashes of four out of six devices.

### Testing File System Implementations on Layered Models

* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Testing_file_system_implementations_on_layered_models.pdf)

* **Abstract:** Generating high-quality system call sequences is not only important to testing file system implementations, but also challenging due to the astronomically large input space. This paper introduces a new approach to the workload generation problem by building layered models and abstract workloads refinement. This approach is instantiated as a three-layer file system model for file system workload generation. In a short-period experiment run, sequential workloads (system call sequences) manifested over a thousand crashes in mainline Linux Kernel file systems, with 12 previously unknown bugs being reported. We also provide evidence that such workloads benefit other domain-specific testing techniques including crash consistency testing and concurrency testing.

### RIBDetector: an RFC-guided Inconsistency Bug Detecting Approach for Protocol Implementations

* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/RIBDetector_an_RFC-guided_Inconsistency_Bug_Detecting_Approach_for_Protocol_Implementations.pdf)
* **Abstract:** The implementations of network protocols must comply with rules described in their Request For Comments (RFC) Standards. Developers’ misunderstanding or negligence of RFCs may bring in inconsistency bugs, which could further cause incorrect behaviors, interoperability issues, or critical security implications. Detecting such bugs is difficult as they usually result in silent erroneous effect. Prior work on RFC-directed inconsistency bug detection usually deal with a certain protocol or ad-hoc properties in RFCs. In this paper, we present RIBDetector, an approach focusing on statically and efficiently locating inconsistency bugs that could be triggered by hand-crafted network packets in protocol implementations. Given an implementation, its corresponding RFCs and a user-provided configuration file, our approach automatically extracts rules about packet format, state transition and error handling from RFCs into a uniform format which dictates condition checks that must be performed before taking particular operations. Then we leverage common programming conventions to identify corresponding locations of the conditions and operations in implementations and use a light-weight predominator-based algorithm to detect violations of RFC rules. We implemented a prototype of RIBDetector and demonstrated its efficacy by applying it on 14 implementations of 5 network protocols. For implementations varying in size from 1.5 to 141.3 KLOC, RIBDetector consumes 17.57 seconds on average to finish its analysis. We have detected 23 new inconsistency bugs, 6 of which are confirmed and fixed by developers.

### UNIFUZZ: A Holistic and Pragmatic Metrics-Driven Platform for Evaluating Fuzzers

* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/UNIFUZZ%20A%20Holistic%20and%20Pragmatic%20Metrics-Driven%20Platform%20for%20Evaluating%20Fuzzers.pdf)
* **Abstract:** A flurry of fuzzing tools (fuzzers) have been proposed in the literature, aiming at detecting software vulnerabilities effectively and efficiently. To date, it is however still challenging to compare fuzzers due to the inconsistency of the benchmarks, performance metrics, and/or environments for evaluation, which buries the useful insights and thus impedes the discovery of promising fuzzing primitives. In this paper, we design and develop UNIFUZZ, an open-source and metrics-driven platform for assessing fuzzers in a comprehensive and quantitative manner. Specifically, UNIFUZZ to date has incorporated 35 usable fuzzers, a benchmark of 20 real-world programs, and six categories of performance metrics. We first systematically study the usability of existing fuzzers, find and fix a number of flaws, and integrate them into UNIFUZZ. Based on the study, we propose a collection of pragmatic performance metrics to evaluate fuzzers from six complementary perspectives. Using UNIFUZZ, we conduct in-depth evaluations of several prominent fuzzers including AFL, AFLFast, Angora, Honggfuzz, MOPT,
QSYM, T-Fuzz and VUzzer64. We find that none of them outperforms the others across all the target programs, and that using a single metric to assess the performance of a fuzzer may lead to unilateral conclusions, which demonstrates the significance of comprehensive metrics. Moreover, we identify and investigate previously overlooked factors that may significantly affect a fuzzer’s performance, including instrumentation methods and crash analysis tools. Our empirical results show that they are critical to the evaluation of a fuzzer. We hope that our findings can shed light on reliable fuzzing evaluation, so that we can discover promising fuzzing primitives to effectively facilitate fuzzer designs in the future.

### Arbiter: Bridging the Static and Dynamic Divide in Vulnerability Discovery on Binary Programs

* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Arbiter_Bridging_the_Static_and_Dynamic_Divide.pdf)
* **Abstract:** In spite of their effectiveness in the context of vulnerability
discovery, current state-of-the-art binary program analysis approaches are limited by inherent trade-offs between accuracy and scalability. In this paper, we identify a set of vulnerability properties that can aid both static and dynamic vulnerability detection techniques, improving the precision of the former and the scalability of the latter. By carefully integrating static and dynamic techniques, we detect vulnerabilities that exhibit these properties in real-world programs at a large scale.
We implemented our technique, making several advancements in the analysis of binary code, and created a prototype called ARBITER. We demonstrate the effectiveness of our approach with a large-scale evaluation on four common vulnerability classes: CWE-131 (Incorrect Calculation of Buffer Size), CWE-252 (Unchecked Return Value), CWE-134 (Uncontrolled Format String), and CWE-337 (Predictable Seed in Pseudo-Random Number Generator). We evaluated our approach on more than 76,516 x86-64 binaries in the Ubuntu repositories and discovered new vulnerabilities, including a flaw inserted into programs during compilation.

### FIRM-AFL: High-Throughput Greybox Fuzzing of IoT Firmware via Augmented Process Emulation

* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/firmafl.pdf)
* **Abstract:** Cyber attacks against IoT devices are a severe threat. These
attacks exploit software vulnerabilities in IoT firmware.
Fuzzing is an effective software testing technique for vulnerability discovery. In this work, we present FIRM-AFL, the
first high-throughput greybox fuzzer for IoT firmware. FIRMAFL addresses two fundamental problems in IoT fuzzing.
First, it addresses compatibility issues by enabling fuzzing for
POSIX-compatible firmware that can be emulated in a system
emulator. Second, it addresses the performance bottleneck
caused by system-mode emulation with a novel technique
called augmented process emulation. By combining systemmode emulation and user-mode emulation in a novel way,
augmented process emulation provides high compatibility as
system-mode emulation and high throughput as user-mode
emulation. Our evaluation results show that (1) FIRM-AFL is
fully functional and capable of finding real-world vulnerabilities in IoT programs; (2) the throughput of FIRM-AFL is on
average 8.2 times higher than system-mode emulation based
fuzzing; and (3) FIRM-AFL is able to find 1-day vulnerabilities much faster than system-mode emulation based fuzzing,
and is able to find 0-day vulnerabilities.


### Automatic Firmware Emulation through Invalidity-guided Knowledge Inference
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/uemu.pdf)
* **Abstract:** Emulating firmware for microcontrollers is challenging due to the tight coupling between the hardware and firmware.
This has greatly impeded the application of dynamic analysis
tools to firmware analysis. The state-of-the-art work automatically models unknown peripherals by observing their
access patterns, and then leverages heuristics to calculate the
appropriate responses when unknown peripheral registers are
accessed. However, we empirically found that this approach
and the corresponding heuristics are frequently insufficient to
emulate firmware. In this work, we propose a new approach
called µEmu to emulate firmware with unknown peripherals.
Unlike existing work that attempts to build a general model
for each peripheral, our approach learns how to correctly emulate firmware execution at individual peripheral access points.
It takes the image as input and symbolically executes it by
representing unknown peripheral registers as symbols. During
symbolic execution, it infers the rules to respond to unknown
peripheral accesses. These rules are stored in a knowledge
base, which is referred to during the dynamic firmware analysis. µEmu achieved a passing rate of 95% in a set of unit tests
for peripheral drivers without any manual assistance. We also
evaluated µEmu with real-world firmware samples and new
bugs were discovered.

### TCP-Fuzz: Detecting Memory and Semantic Bugs in TCP Stacks with Fuzzing
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/tcp.pdf)
* **Abstract:** TCP stacks provide reliable data transmission in network, and thus they should be correctly implemented and well tested to ensure reliability and security. However, testing TCP stacks is difficult. First, a TCP stack accepts packets and system calls that have dependencies between each other, and thus generating effective test cases is challenging. Second, a TCP stack has various complex state transitions, but existing testing approaches target covering states instead of covering state transitions, and thus their testing coverage is limited. Finally, our study of TCP stack commits shows that 87% of bug-fixing commits are related to semantic bugs (such as RFC violations), but existing bug sanitizers can detect only memory bugs not semantic bugs. 
In this paper, we design a novel fuzzing framework named TCP-Fuzz, to effectively test TCP stacks and detect bugs. TCP-Fuzz consists of three key techniques: (1) a dependency-based strategy that considers dependencies between packets and system calls, to generate effective test cases; (2) a transition-guided fuzzing approach that uses a new coverage metric named branch transition as program feedback, to improve the coverage of state transitions; (3) a differential checker that compares the outputs of multiple TCP stacks for the same inputs, to detect semantic bugs. We have evaluated TCP-Fuzz on five widely-used TCP stacks (TLDK, F-Stack, mTCP, FreeBSD TCP and Linux TCP), and find 56 real bugs (including 8 memory bugs and 48 semantic bugs). 40 of these bugs have been confirmed by related developers.

### SweynTooth: Unleashing Mayhem over Bluetooth Low Energy
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/bt.pdf)
* **Abstract:** The Bluetooth Low Energy (BLE) is a promising short-range communication technology for Internet-of-Things (IoT) with reduced energy consumption. Vendors implement BLE protocols in their manufactured devices compliant to Bluetooth Core Specification. Recently, several vulnerabilities were discovered in the BLE protocol implementations of a few specific products via a manual approach. Considering the diversity and usage of BLE devices as well as the complexity of BLE protocols, we have developed a systematic and comprehensive testing framework, which, as an automated and general-purpose approach, can effectively fuzz any BLE protocol implementation. Our framework runs in a central device and tests a BLE device when the latter gets connected to the central as a peripheral. Our framework incorporates a state machine model of the suite of BLE protocols and monitors the peripheral’s state through its responses. With the state machine and current state of the central, our framework either sends malformed packets or normal packets at a wrong time, or both, to the peripheral and awaits an expected response. Anomalous behaviours of the peripheral, e.g., a non-compliant response or unresponsiveness, indicate potential vulnerabilities in its BLE protocol implementation. To maximally expose such anomalies for a BLE device, our framework employs an optimization function to direct the fuzzing process. As of today, we have tested 12 devices from eight vendors and four IoT products, with a total of 11 new vulnerabilities discovered and 13 new Common  Vulnerability Exposure (CVE) IDs assigned. We call such a bunch of vulnerabilities as SWEYNTOOTH, which highlights the efficacy of our framework.

### Sharing More and Checking Less: Leveraging Common Input Keywords to Detect Bugs in Embedded Systems
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/SaTC.pdf)
* **Abstract:** IoT devices have brought invaluable convenience to our daily life. However, their pervasiveness also amplifies the impact of security vulnerabilities. Many popular vulnerabilities of embedded systems reside in their vulnerable web services. Unfortunately, existing vulnerability detection methods cannot effectively nor efficiently analyze such web services: they either introduce heavy execution overheads or have many
false positives and false negatives.  
In this paper, we propose a novel static taint checking solution, SaTC, to effectively detect security vulnerabilities in
web services provided by embedded devices. Our key insight
is that, string literals on web interfaces are commonly shared
between front-end files and back-end binaries to encode user
input. We thus extract such common keywords from the frontend, and use them to locate reference points in the back-end,
which indicate the input entry. Then, we apply targeted dataflow analysis to accurately detect dangerous uses of the untrusted user input. We implemented a prototype of SaTC and
evaluated it on 39 embedded system firmwares from six popular vendors. SaTC discovered 33 unknown bugs, of which 30
are confirmed by CVE/CNVD/PSV. Compared to the state-ofthe-art tool KARONTE, SaTC found significantly more bugs
on the test set. It shows that, SaTC is effective in discovering
bugs in embedded systems.

### FirmAE: Towards Large-Scale Emulation of IoT Firmware for Dynamic Analysis
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/FirmAE.pdf)
* **Abstract:** One approach to assess the security of embedded IoT devices is
applying dynamic analysis such as fuzz testing to their firmware in
scale. To this end, existing approaches aim to provide an emulation
environment that mimics the behavior of real hardware/peripherals.
Nonetheless, in practice, such approaches can emulate only a small
fraction of firmware images. For example, Firmadyne, a state-of-the-
art tool, can only run 183 (16.28%) of 1,124 wireless router/IP-camera
images that we collected from the top eight manufacturers. Such a
low emulation success rate is caused by discrepancy in the real and
emulated firmware execution environment.  
In this study, we analyzed the emulation failure cases in a large-
scale dataset to figure out the causes of the low emulation rate. We
found that widespread failure cases often avoided by simple heuris-
tics despite having different root causes, significantly increasing the
emulation success rate. Based on these findings, we propose a tech-
nique, arbitrated emulation, and we systematize several heuristics
as arbitration techniques to address these failures. Our automated
prototype, FirmAE, successfully ran 892 (79.36%) of 1,124 firmware
images, including web servers, which is significantly (≈4.8x) more
images than that run by Firmadyne. Finally, by applying dynamic
testing techniques on the emulated images, FirmAE could check
320 known vulnerabilities (306 more than Firmadyne), and also find
12 new 0-days in 23 devices.

### Binary Code Is Not Easy
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Binary_Code_Is_Not_Easy.pdf)
* **Abstract:** Binary code analysis is an enabling technique for many applications. Modern compilers and run-time libraries have introduced significant complexities to binary code, which negatively affect the capabilities of binary analysis tool kits to analyze binary code, and may cause tools to report inaccurate information about binary code. Analysts may hence be confused and applications based on these tool kits may have degrading quality. We examine the problem of constructing control flow graphs from binary code and labeling the graphs with accurate function boundary annotations. We identified several challenging code constructs that represent hard-toanalyze aspects of binary code, and show code examples for each code construct. As part of this discussion, we present new code parsing algorithms in our open source Dyninst tool kit that support these constructs, including a new model for describing jump tables that improves our ability to precisely determine the control flow targets, a new interprocedural analysis to determine when a function is non-returning, and techniques for handling tail calls. We evaluated how various tool kits fare when handling these code constructs with real software as well as test binaries patterned after each challenging code construct we found in real software.

### Recovery of Variable and Data Structure via Probabilistic Analysis for Stripped Binary
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/OSPREY_Recovery_of_Variable_and_Data_Structure_via_Probabilistic_Analysis_for_Stripped_Binary.pdf)
* **Abstract:** Recovering variables and data structure information
from stripped binary is a prominent challenge in binary program
analysis. While various state-of-the-art techniques are effective
in specific settings, such effectiveness may not generalize. This
is mainly because the problem is inherently uncertain due to
the information loss in compilation. Most existing techniques
are deterministic and lack a systematic way of handling such
uncertainty. We propose a novel probabilistic technique for variable and structure recovery. Random variables are introduced
to denote the likelihood of an abstract memory location having
various types and structural properties such as being a field
of some data structure. These random variables are connected
through probabilistic constraints derived through program analysis. Solving these constraints produces the posterior probabilities
of the random variables, which essentially denote the recovery
results. Our experiments show that our technique substantially
outperforms a number of state-of-the-art systems, including
IDA, Ghidra, Angr, and Howard. Our case studies demonstrate
the recovered information improves binary code hardening and
binary decompilation.


### Decompilation of Binaries into LLVM IR for Automated Analysis
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/ghidra2llvm.pdf)


### Analyzing Memory Accesses in x86 Executables
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Analyzing_Memory_Accesses_in_x86_Executables.pdf)
* **Abstract:** This paper concerns static-analysis algorithms for analyzing x86 executables.
The aim of the work is to recover intermediate representations that are similar to those that
can be created for a program written in a high-level language. Our goal is to perform this
task for programs such as plugins, mobile code, worms, and virus-infected code. For such
programs, symbol-table and debugging information is either entirely absent, or cannot be
relied upon if present; hence, the technique described in the paper makes no use of symboltable/debugging information. Instead, an analysis is carried out to recover information about
the contents of memory locations and how they are manipulated by the executable.

### WYSINWYX: What you see is not what you eXecute
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/What_your_firmware_tells_you_is_not_how_you_should_emulate_it.pdf)
* **Abstract:** Over the last seven years, we have developed static-analysis methods to recover a good approximation to the variables and dynamically allocated memory objects of a stripped executable, and
to track the flow of values through them. The article presents the algorithms that we developed,
explains how they are used to recover Intermediate Representations (IRs) from executables that
are similar to the IRs that would be available if one started from source code, and describes their
application in the context of program understanding and automated bug hunting.
Unlike algorithms for analyzing executables that existed prior to our work, the ones presented
in this article provide useful information about memory accesses, even in the absence of debugging
information. The ideas described in the article are incorporated in a tool for analyzing Intel x86


### All You Ever Wanted to Know About Dynamic Taint Analysis and Forward Symbolic Execution
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/All_You_Ever_Wanted_to_Know_about_Dynamic_Taint_Analysis_and_Forward_Symbolic_Execution_but_Might_Have_Been_Afraid_to_Ask.pdf)
* **Abstract:** Dynamic taint analysis and forward symbolic execution are quickly becoming staple techniques in security
analyses. Example applications of dynamic taint analysis and forward symbolic execution include malware analysis, input filter generation, test case generation, and vulnerability discovery. Despite the widespread usage of these two techniques, there has been little effort to formally define the algorithms and summarize the critical issues that arise when these techniques are used in typical security contexts.  
The contributions of this paper are two-fold. First, we precisely describe the algorithms for dynamic taint analysis and forward symbolic execution as extensions to the run-time semantics of a general language. Second, we highlight important implementation choices, common pitfalls, and considerations when using these techniques in a security context.


### A Formal Semantics for P-Code
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Pcode.pdf)
* **Abstract:** Decompilation is currently a widely used tool in reverse
engineering and exploit detection in binaries. Ghidra, developed by the
National Security Agency, is one of the most popular decompilers. It
decompiles binaries to high P-Code, from which the final decompila-
tion output in C code is generated. Ghidra allows users to work with
P-Code, so users can analyze the intermediate representation directly.
Several projects make use of this to build tools that perform verifica-
tion, decompilation, taint analysis and emulation, to name a few. P-
Code lacks a formal semantics, and its documentation is limited. It has
a notoriously subtle semantics, which makes it hard to do any sort of
analysis on P-Code. We show that P-Code, as-is, cannot be given an
executable semantics. In this paper, we augment P-Code and define a
complete, executable, formal semantics for it. This is done by looking at
the documentation and the decompilation results of binaries with known
source code. The development of a formal P-Code semantics uncovered
several issues in Ghidra, P-Code, and the documentation. We show that
these issues affect projects that rely on Ghidra and P-Code. We evaluate
the executability of our semantics by building a P-Code interpreter that
directly uses our semantics. Our work uncovered several issues in Ghidra
and allows Ghidra users to better leverage P-Code.


### Selectivetaint: Efficient Data Flow Tracking With Static Binary Rewriting
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/SelectiveTaint.pdf)
* **Abstract:** Taint analysis has been widely used in many security applica-
tions such as exploit detection, information flow tracking, mal-
ware analysis, and protocol reverse engineering. State-of-the-
art taint analysis tools are usually built atop dynamic binary
instrumentation, which instruments at every possible instruc-
tion, and rely on runtime information to decide whether a par-
ticular instruction involves taint or not, thereby usually having
high performance overhead. This paper presents SELECTIVE-
TAINT, an efficient selective taint analysis framework for bi-
nary executables. The key idea is to selectively instrument the
instructions involving taint analysis using static binary rewrit-
ing instead of dynamic binary instrumentation. At a high level,
SELECTIVETAINT statically scans taint sources of interest in
the binary code, leverages value set analysis to conservatively
determine whether an instruction operand needs to be tainted
or not, and then selectively taints the instructions of interest.
We have implemented SELECTIVETAINT and evaluated it
with a set of binary programs including 16 coreutils (focusing
on file I/O) and five network daemon programs (focusing
on network I/O) such as nginx web server. Our evaluation
results show that the binaries statically instrumented by SE-
LECTIVETAINT has superior performance compared to the
state-of-the-art dynamic taint analysis frameworks (e.g., 1.7x
faster than that of libdft).

### Context Sensitivity without Contexts
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Context_Sensitivity_without_Contexts.pdf)
* **Abstract:** Over the past decades, context sensitivity has been considered as one of the most effective ideas for improving
the precision of pointer analysis for Java. Different from the extremely fast context-insensitivity approach,
context sensitivity requires every program method to be analyzed under different contexts for separating
the static abstractions of different dynamic instantiations of the method’s variables and heap objects, and
thus reducing spurious object flows introduced by method calls. However, despite great precision benefits,
as each method is equivalently cloned and analyzed under each context, context sensitivity brings heavy
efficiency costs. Recently, numerous selective context-sensitive approaches have been put forth for scaling
pointer analysis to large and complex Java programs by applying contexts only to the selected methods
while analyzing the remaining ones context-insensitively; however, because the selective approaches do not
fundamentally alter the primary methodology of context sensitivity (and do not thus remove its efficiency
bottleneck), they produce much improved but still limited results.  
In this work, we present a fundamentally different approach called Cut-Shortcut for fast and precise
pointer analysis for Java. Its insight is simple: the main effect of cloning methods under different contexts is to
filter spurious object flows that have been merged inside a callee method; from the view of a typical pointer
flow graph (PFG), such effect can be simulated by cutting off (Cut) the edges that introduce precision loss to
certain pointers and adding Shortcut edges directly from source pointers to the target ones circumventing the
method on PFG. As a result, we can achieve the effect of context sensitivity without contexts. We identify three
general program patterns and develop algorithms based on them to safely cut off and add shortcut edges on PFG,
formalize them and formally prove the soundness. To comprehensively validate Cut-Shortcut’s effectiveness,
we implement two versions of Cut-Shortcut for two state-of-the-art pointer analysis frameworks for Java,
one in Datalog for the declarative Doop and the other in Java for the imperative Tai-e, and we consider all
the large and complex programs used in recent literatures that meet the experimental requirements. The
evaluation results are extremely promising: Cut-Shortcut is even able to run faster than context insensitivity
for most evaluated programs while obtaining high precision that is comparable to context sensitivity (if
scalable) in both frameworks. This is for the first time that we have been able to achieve such a good efficiency
and precision trade-off for those hard-to-analyze programs, and we hope Cut-Shortcut could offer new
perspectives for developing more effective pointer analysis for Java in the future.


### BDA: Practical Dependence Analysis for Binary Executables by Unbiased Whole-Program Path Sampling and Per-Path Abstract Interpretation
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/BDA.pdf)
* **Abstract:** Binary program dependence analysis determines dependence between instructions and hence is important for
many applications that have to deal with executables without any symbol information. A key challenge is to
identify if multiple memory read/write instructions access the same memory location. The state-of-the-art
solution is the value set analysis (VSA) that uses abstract interpretation to determine the set of addresses
that are possibly accessed by memory instructions. However, VSA is conservative and hence leads to a large
number of bogus dependences and then substantial false positives in downstream analyses such as malware
behavior analysis. Furthermore, existing public VSA implementations have difficulty scaling to complex
binaries. In this paper, we propose a new binary dependence analysis called BDA enabled by a randomized
abstract interpretation technique. It features a novel whole program path sampling algorithm that is not
biased by path length, and a per-path abstract interpretation avoiding precision loss caused by merging paths
in traditional analyses. It also provides probabilistic guarantees. Our evaluation on SPECINT2000 programs
shows that it can handle complex binaries such as gcc whereas VSA implementations from the-state-of-art
platforms have difficulty producing results for many SPEC binaries. In addition, the dependences reported by
BDA are 75 and 6 times smaller than Alto, a scalable binary dependence analysis tool, and VSA, respectively,
with only 0.19% of true dependences observed during dynamic execution missed (by BDA). Applying BDA to
call graph generation and malware analysis shows that BDA substantially supersedes the commercial tool
IDA in recovering indirect call targets and outperforms a state-of-the-art malware analysis tool Cuckoo by
disclosing 3 times more hidden payloads.

### Generating models of infinite-state communication protocols using regular inference with abstraction
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Generating_models_of_infinite_state_communication_protocols_using_regular_inference_with_abstraction.pdf)
* **Abstract:** In order to facilitate model-based verification and validation, effort is underway
to develop techniques for generating models of communication system components from
observations of their external behavior. Most previous such work has employed regular
inference techniques which generate modest-size finite-state models. They typically sup-
press parameters of messages, although these have a significant impact on control flow in
many communication protocols. We present a framework, which adapts regular inference
to include data parameters in messages and states for generating components with large or
infinite message alphabets. A main idea is to adapt the framework of predicate abstraction,
successfully used in formal verification. Since we are in a black-box setting, the abstraction
must be supplied externally, using information about how the component manages data para-
meters. We have implemented our techniques by connecting the LearnLib tool for regular
inference with an implementation of session initiation protocol (SIP) in ns-2 and an imple-
mentation of transmission control protocol (TCP) in Windows 8, and generated models of
SIP and TCP components.

### VERI: A Large-scale Open-Source Components Vulnerability Detection in IoT Firmware
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/veri.pdf)
* **Abstract:** IoT device manufacturers integrate open-source components (OSCs) to serve necessary and common func-
tions for facilitating firmware development. However, outdated versions of OSC conceal N-day vulnera-
bilities and continue to function on IoT devices. The security risks can be predicted once we can identify
the OSC versions employed in the firmware. Existing works make attempts at OSC version identifica-
tion but fail to perform vulnerability detection on a large-scale IoT firmware due to i) unsuitable version
identification method for IoT firmware scenario. ii) the lack of a large-scale version-vulnerability rela-
tion database. To this end, we propose a system VERI for large-scale vulnerability detection based on
lightweight version identification. First, for OSC version identification, VERI leverages symbolic execution
with static analysis to identify exact OSC versions even though there are many version-like strings in OSC.
Second, VERI employs a deep learning-based method to extract OSC names and vulnerable version ranges
from vulnerability descriptions, constructs and maintains an OSC version-vulnerability relation database
to serve the vulnerability detection. Finally, VERI polls the relation database to confirm the N-day security
risk of the OSC with identified version. The evaluation results show that VERI achieves 96.43% accuracy
with high efficiency in OSC version identification. Meanwhile, the deep learning model accurately extracts
the OSC names and versions from vulnerability descriptions dataset with 97.19% precision and 96.56% re-
call. Based on the model, we build a large-scale version-vulnerability relation database. Furthermore, we
utilize VERI to conduct a large-scale analysis on 28,890 firmware and find 38,654 vulnerable OSCs with
266,109 N-day vulnerabilities, most of which are with high risks. From the detection results, we find that
after the official patch for the vulnerability is released, manufacturers delay an average of 473 days to
patch the firmware.

### VulHawk: Cross-architecture Vulnerability Detection with Entropy-based Binary Code Search
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/vulhawk.pdf)
* **Abstract:** Code reuse is widespread in software development. It brings a heavy spread of vulnerabilities, threatening software security. Unfortunately, with the development and deployment of the Internet of Things (IoT), the harms of code reuse are magnified. Binary code search is a viable way to find these hidden vulnerabilities. Facing IoT firmware images compiled by different compilers with different optimization levels from different architectures, the existing methods are hard to fit these
complex scenarios. In this paper, we propose a novel intermediate representation function model, which is an architecture-agnostic model for cross-architecture binary code search. It lifts binary
code into microcode and preserves the main semantics of binary
functions via complementing implicit operands and pruning
redundant instructions. Then, we use natural language processing
techniques and graph convolutional networks to generate function
embeddings. We call the combination of a compiler, architecture,
and optimization level as a file environment, and take a divide-
and-conquer strategy to divide a similarity calculation problem
of C^2_N cross-file-environment scenarios into N − 1 embedding
transferring sub-problems. We propose an entropy-based adapter
to transfer function embeddings from different file environments
into the same file environment to alleviate the differences caused
by various file environments. To precisely identify vulnerable
functions, we propose a progressive search strategy to supplement
function embeddings with fine-grained features to reduce false
positives caused by patched functions. We implement a prototype
named VulHawk and conduct experiments under seven different
tasks to evaluate its performance and robustness. The experiments
show VulHawk outperforms Asm2Vec, Asteria, BinDiff, GMN,
PalmTree, SAFE, and Trex.


### Challenges and Solutions for Embedded and Networked Aerospace Software Systems
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Challenges_and_Solutions_for_Embedded_and_Networked_Aerospace_Software_Systems.pdf)
* **Abstract:** Aerospace systems are increasingly dependent
upon software for their functionality, with associated software
spanning a wide range of application domains. These include
aircraft and spacecraft flight controls, mission computing,
weapons management, command and control, surveillance,
sensor management and processing, telemetry, and more.
Understanding of their unique challenges has driven technol-
ogy development on many fronts associated both with the
productsVsuch as real-time component-based application
frameworks, supporting middleware, and algorithmsVand
the processes and tools by which they are createdVsuch as
model-based development and integration, automated code
generation, simulations, and desktop test environments. This
paper describes a number of these domains and challenges,
future directions associated with networking and systems of
systems, and technologies facilitating their development within
The Boeing Company.


### Physical Devices-Agnostic Hybrid Fuzzing of IoT Firmware
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Physical_Devices-Agnostic_Hybrid_Fuzzing_of_IoT_Firmware.pdf)
* **Abstract:** With the rapid expansion of the Internet of Things,
a vast number of microcontroller-based IoT devices are now
susceptible to attacks through the Internet. Vulnerabilities within
the firmware are one of the most important attack surfaces.
Fuzzing has emerged as one of the most effective techniques for
identifying such vulnerabilities. However, when applied to IoT
firmware, several challenges arise, including: (1) the inability
of firmware to execute properly in the absence of peripherals,
(2) the lack of support for exploring input spaces of multiple
peripherals, (3) difficulties in instrumenting and gathering feed-
back, and (4) the absence of a fault detection mechanism. To
address these challenges, we have developed and implemented
an innovative peripheral-independent hybrid fuzzing tool called
FirmHybirdFuzzer. This tool enables testing of microcontroller-
based firmware without reliance on specific peripheral hardware.
First, a unified virtual peripheral was integrated to model the be-
haviors of various peripherals, thus enabling the physical devices-
agnostic firmware execution. Then, a hybrid event generation
approach was used to generate inputs for different peripheral
accesses. Furthermore, two-level coverage feedback was collected
to optimize the testcase generation. Finally, a plugin-based
fault detection mechanism was implemented to identify typical
memory corruption vulnerabilities. A Large-scale experimental
evaluation has been performed to show FirmHybirdFuzzer’s
effectiveness and efficiency.

### Adaptive and Effective Fuzzing: A Data-Driven Approach
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Adaptive_and_effective_fuzzing_a_data_driven_approach.pdf)
* **Abstract:** Security vulnerabilities have a large real-world impact, from ransomware attacks costing
billions of dollars every year to sensitive data breaches in government, military and industry.
Fuzzing is a popular technique to discover these vulnerabilities in an automated fashion. Industries
have poured tons of resources into building large-scale fuzzing factories (e.g., Google’s ClusterFuzz
and Microsoft’s OneFuzz) to test their products and make their product more secure. Despite the
wide application of fuzzing in industry, there remain many issues constraining its performance. One
fundamental limitation is the rule-based design in fuzzing. Rule-based fuzzers heavily rely on a set
of static rules or heuristics. These fixed rules are summarized from human experience, hence failing
to generalize on a diverse set of programs.
In this dissertation, we present an adaptive and effective fuzzing framework in data-driven approach.
A data-driven fuzzer makes decisions based on the analysis and reasoning of data rather than the
static rules. Hence it is more adaptive, effective, and flexible than a typical rule-based fuzzer. More
interestingly, the data-driven approach can bridge the connection from fuzzing to various
data-centric domains (e.g., machine learning, optimizations and social network), enabling
sophisticated designs in the fuzzing framework.
A general fuzzing framework consists of two major components: seed scheduling and seed
mutation. The seed scheduling module selects a seed from a seed corpus that includes multiple
testcases. Then seed mutation module applies perturbation on the selected seed to generate a newtestcase. First, we present Neuzz, the first machine learning (ML) based general-purpose fuzzer that
adopts ML to seed mutation and greatly improves fuzzing performance. Then we present MTFuzz,
a follow-up work of Neuzz by including diverse data into ML to generate effective seed mutations.
In the end, we present K-Scheduler, a fuzzer-agnostic seed scheduling algorithm in data-driven
approach. K-Scheduler leverages the graph data (i.e., inter-procedural control flow graph) and
dynamic coverage data (i.e., code coverage bitmap) to construct a dynamic graph and schedule
seeds by the graph centrality scores on that graph. It can significantly improve the fuzzing
performance than the-state-of-art seed schedulers on various fuzzers widely-used in the industry.

### SoK: All You Ever Wanted to Know About x86/x64 Binary Disassembly But Were Afraid to Ask
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/SoK_All_You_Ever_Wanted_to_Know_About_x86_x64_Binary_Disassembly_But_Were_Afraid_to_Ask.pdf)
* **Abstract:** Disassembly of binary code is hard, but necessary
for improving the security of binary software. Over the past
few decades, research in binary disassembly has produced many
tools and frameworks, which have been made available to
researchers and security professionals. These tools employ a
variety of strategies that grant them different characteristics.
The lack of systematization, however, impedes new research in
the area and makes selecting the right tool hard, as we do
not understand the strengths and weaknesses of existing tools.
In this paper, we systematize binary disassembly through the
study of nine popular, open-source tools. We couple the manual
examination of their code bases with the most comprehensive
experimental evaluation (thus far) using 3,788 binaries. Our
study yields a comprehensive description and organization of
strategies for disassembly, classifying them as either algorithm
or else heuristic. Meanwhile, we measure and report the impact
of individual algorithms on the results of each tool. We find that
while principled algorithms are used by all tools, they still heavily
rely on heuristics to increase code coverage. Depending on the
heuristics used, different coverage-vs-correctness trade-offs come
in play, leading to tools with different strengths and weaknesses.
We envision that these findings will help users pick the right tool
and assist researchers in improving binary disassembly.

### Compiler-assisted Code Randomization
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Compiler-Assisted_Code_Randomization.pdf)
* **Abstract:** Despite decades of research on software diversi-
fication, only address space layout randomization has seen
widespread adoption. Code randomization, an effective defense
against return-oriented programming exploits, has remained an
academic exercise mainly due to i) the lack of a transparent
and streamlined deployment model that does not disrupt existing
software distribution norms, and ii) the inherent incompatibility
of program variants with error reporting, whitelisting, patching,
and other operations that rely on code uniformity. In this
work we present compiler-assisted code randomization (CCR), a
hybrid approach that relies on compiler–rewriter cooperation
to enable fast and robust fine-grained code randomization on
end-user systems, while maintaining compatibility with existing
software distribution models. The main concept behind CCR
is to augment binaries with a minimal set of transformation-
assisting metadata, which i) facilitate rapid fine-grained code
transformation at installation or load time, and ii) form the basis
for reversing any applied code transformation when needed, to
maintain compatibility with existing mechanisms that rely on
referencing the original code. We have implemented a prototype
of this approach by extending the LLVM compiler toolchain,
and developing a simple binary rewriter that leverages the
embedded metadata to generate randomized variants using basic
block reordering. The results of our experimental evaluation
demonstrate the feasibility and practicality of CCR, as on average
it incurs a modest file size increase of 11.46% and a negligible
runtime overhead of 0.28%, while it is compatible with link-time
optimization and control flow integrity

### SFADiff: Automated Evasion Attacks and Fingerprinting Using Black-box Differential Automata Learning
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/SFADiff.pdf)
* **Abstract:** Finding differences between programs with similar functionality is an important security problem as such differences can be used for fingerprinting or creating evasion attacks against security software like Web Application Firewalls (WAFs)
which are designed to detect malicious inputs to web applications. In this paper, we present SFADiff, a black-box
differential testing framework based on Symbolic Finite Automata (SFA) learning. SFADiff can automatically find differences between a set of programs with comparable functionality. Unlike existing differential testing techniques, instead of searching for each difference individually, SFADiff infers SFA models of the target programs using black-box queries and systematically enumerates the differences between the inferred SFA models. All differences between the inferred models are checked against the corresponding programs. Any difference between the models, that does not result in a difference between the corresponding programs,
is used as a counterexample for further refinement of the inferred models. SFADiff’s model-based approach, unlike existing differential testing tools, also support fully automated root cause analysis in a domain-independent manner.  
We evaluate SFADiff in three different settings for finding discrepancies between: (i) three TCP implementations,
(ii) four WAFs, and (iii) HTML/JavaScript parsing implementations in WAFs and web browsers. Our results demonstrate that SFADiff is able to identify and enumerate the differences systematically and eciently in all these settings. We show that SFADiff is able to find differences not only between different WAFs but also between different versions of the same WAF. SFADiff is also able to discover three previously-unknown differences between the HTML/JavaScript parsers of two popular WAFs (PHPIDS 0.7 and Expose 2.4.0) and the corresponding parsers of Google Chrome, Firefox, Safari, and Internet Explorer. We confirm that all these differences can be used to evade the WAFs and launch successful cross-site scripting attacks.


### Back in Black: Towards Formal, Black Box Analysis of Sanitizers and Filters
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/SFADiff.pdf)
We tackle the problem of analyzing filter and sanitizer programs remotely, i.e. given only the ability to query the targeted program and observe the output. We focus on two important and widely used program classes: regular expression (RE) filters and string sanitizers. We demonstrate that existing tools from machine learning that are available for analyzing RE filters, namely automata learning algorithms, require a very large number of queries in order to infer real life RE filters. Motivated by this, we develop the first algorithm that infers symbolic representations of automata in the standard membership/equivalence query model. We show that our algorithm provides an improvement of x15 times in the number of queries required to learn real life XSS and SQL filters of popular web application firewall systems such as mod-security and PHPIDS. Active learning algorithms require the usage of an equivalence oracle, i.e. an oracle that tests the equivalence of a hypothesis with the target machine. We show that when the goal is to audit a target filter with respect to a set of attack strings from a context free grammar, i.e. find an attack or infer that none exists, we can use the attack grammar to implement the equivalence oracle with a single query to the filter. Our construction finds on average 90% of the target filter states when no attack exists and is very effective in finding attacks when they are present.  
For the case of string sanitizers, we show that existing algorithms for inferring sanitizers modelled as Mealy Machines are not only inefficient, but lack the expressive power to be able to infer real life sanitizers. We design two novel extensions to existing algorithms that allow one to infer sanitizers represented as single-valued transducers. Our algorithms are able to infer many common sanitizer functions such as HTML encoders and decoders. Furthermore, we design an algorithm to convert the inferred models into BEK programs, which allows for further applications such as cross checking different sanitizer implementations and cross compiling sanitizers into different languages supported by the BEK backend. We showcase the power of our techniques by utilizing our black-box inference algorithms to perform an equivalence checking between different HTML encoders including the encoders from Twitter, Facebook and Microsoft Outlook email, for which no implementation is publicly available.

### Learning Regular Sets from Queries and Counterexamples
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Learning_regular_sets_from_queries_and_counterexamples.pdf)
* **Abstract:** The problem of identifying an unknown regular set from examples of its members
and nonmembers is addressed. It is assumed that the regular set is presented by a
minimaMy adequate Teacher, which can answer membership queries about the set
and can also test a conjecture and indicate whether it is equal to the unknown set
and provide a counterexample if not. (A counterexample is a string in the sym-
metric difference of the correct set and the conjectured set.) A learning algorithm
L* is described that correctly learns any regular set from any minimally adequate
Teacher in time polynomial in the number of states of the minimum dfa for the set
and the maximum length of any counterexample provided by the Teacher. It is
shown that in a stochastic setting the ability of the Teacher to test conjectures may
be replaced by a random sampling oracle, EX( ). A polynomial-time learning
algorithm is shown for a particular problem of context-free language identification.

### Deep Reinforcement Learning for Black-box Testing of Android Apps
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Deep_Reinforcement_Learning_for_Black-box_Testing.pdf)
* **Abstract:** The state space of Android apps is huge, and its thorough exploration during testing remains a significant challenge. The best exploration strategy is highly dependent on the features of the app under test. Reinforcement Learning (RL) is a machine learning technique that learns the optimal strategy to solve a task by trial and error, guided by positive or negative reward, rather than explicit supervision. Deep RL is a recent extension of RL that takes advantage of the learning capabilities of neural networks. Such capabilities make Deep RL suitable for complex exploration spaces such as one of Android apps. However, state-of-the-art, publicly available tools only support basic, Tabular RL. We have developed ARES, a Deep RL approach for black-box testing of Android apps. Experimental results show that it achieves higher coverage and fault revelation than the baselines, including state-of-the-art tools, such as TimeMachine and Q-Testing. We also investigated the reasons behind such performance qualitatively, and we have identified the key features of Android apps that make Deep RL particularly effective on them to be the presence of chained and blocking activities. Moreover, we have developed FATE to fine-tune the hyperparameters of Deep RL algorithms on simulated apps, since it is computationally expensive to carry it out on real apps.

### Fastbot2: Reusable Automated Model-based GUI Testing for Android Enhanced by Reinforcement Learn
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/fastbot2.pdf)
* **Abstract:** We introduce a reusable automated model-based GUI testing technique for Android apps to accelerate the testing cycle. Our key insight is that the knowledge of event-activity transitions from the previous testing runs, i.e., executing which events can reach which activities, is valuable for guiding the follow-up testing runs to quickly
cover major app functionalities. To this end, we propose (1) a probabilistic model to memorize and leverage this knowledge during testing, and (2) design a model-based guided testing strategy (enhanced by a reinforcement learning algorithm). We implemented our technique as an automated testing tool named Fastbot2. The evaluation
on two popular industrial apps (with billions of user installations),
Douyin and Toutiao, shows that Fastbot2 outperforms the state-of-the-art testing tools (Monkey, Ape and Stoat) in both activity coverage and fault detection in the context of continuous testing. To date, Fastbot2 has been deployed in the CI pipeline at ByteDance for nearly two years, and 50.8% of the developer-fixed crash bugs
were reported by Fastbot2, which significantly improves app quality. Fastbot2 has been made publicly available to benefit the community at: https:// github.com/ bytedance/ Fastbot_Androi

### BLEEM: Packet Sequence Oriented Fuzzing for Protocol Implementations
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/bleem.pdf)
* **Abstract:** Protocol implementations are essential components in network infrastructures. Flaws hidden in the implementations can easily render devices vulnerable to adversaries. Therefore, guaranteeing their correctness is important. However, commonly used vulnerability detection techniques, such as fuzz testing, face increasing challenges in testing these implementations due to ineffective feedback mechanisms and insufficient protocol state-space exploration techniques.  
This paper presents BLEEM, a packet-sequence-oriented black-box fuzzer for vulnerability detection of protocol implementations. Instead of focusing on individual packet generation, BLEEM generates packets on a sequence level. It provides an effective feedback mechanism by analyzing the system output sequence noninvasively, supports guided fuzzing by resorting to state-space tracking that encompasses all parties timely, and utilizes interactive traffic information to generate protocol-logic-aware packet sequences. We evaluate BLEEM on 15 widely-used implementations of well-known protocols (e.g., TLS and QUIC). Results show that, compared to the state-of-the-art protocol fuzzers such as Peach, BLEEM achieves substantially higher branch coverage (up to 174.93% improvement) within 24 hours. Furthermore, BLEEM exposed 15 security-critical vulnerabilities in prominent protocol implementations, with 10 CVEs assigned.


### DESPOT: Online POMDP Planning with Regularization
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/DESPOT.pdf)
* **Abstract:** POMDPs provide a principled framework for planning under uncertainty, but are computationally intractable, due to the “curse of dimensionality” and the “curse of history”. This paper presents an online POMDP algorithm that alleviates these difficulties by focusing the search on a set of randomly sampled scenarios. A Determinized Sparse Partially Observable Tree (DESPOT) compactly captures the execution of all policies on these scenarios. Our Regularized DESPOT (R-DESPOT) algorithm searches the DESPOT for a policy, while optimally balancing the size of the policy and its estimated value obtained under the sampled scenarios. We give an output-sensitive performance bound for all policies derived from a DESPOT, and show that R-DESPOT works well if a small optimal policy exists. We also give an anytime algorithm that approximates R-DESPOT. Experiments show strong results, compared with two of the fastest online POMDP algorithms. Source code along with experimental settings are available at http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/


### Reinforcement Learning Based Curiosity-Driven Testing of Android Application
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/qtesting.pdf)
* **Abstract:** Mobile applications play an important role in our daily life, while it still remains a challenge to guarantee their correctness. Model-based and systematic approaches have been applied to Android GUI testing. However, they do not show significant advantages over random approaches because of limitations such as imprecise models and poor scalability. In this paper, we propose Q-testing, a reinforcement learning based approach which benefits from both
random and model-based approaches to automated testing of Android applications. Q-testing explores the Android apps with a curiosity-driven strategy that utilizes a memory set to record part of previously visited states and guides the testing towards unfamiliar functionalities. A state comparison module, which is a neural network trained by plenty of collected samples, is novelly employed to divide different states at the granularity of functional scenarios.
It can determine the reinforcement learning reward in Q-testing and help the curiosity-driven strategy explore different functionalities efficiently. We conduct experiments on 50 open-source applications where Q-testing outperforms the state-of-the-art and state-of-practice Android GUI testing tools in terms of code coverage and fault detection. So far, 22 of our reported faults have been confirmed, among which 7 have been fixed.


### Guided, Stochastic Model-Based GUI Testing of Android Apps
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Guided_Stochastic_Android_GUI_Testing.pdf)
* **Abstract:** Mobile apps are ubiquitous, operate in complex environments and are developed under the time-to-market pressure. Ensuring their correctness and reliability thus becomes an important challenge. This paper introduces Stoat, a novel guided approach to perform stochastic model-based testing on Android apps. Stoat operates in two phases: (1) Given an app as input, it uses dynamic analysis enhanced by a weighted UI exploration strategy and static analysis
to reverse engineer a stochastic model of the app’s GUI interactions; and (2) it adapts Gibbs sampling to iteratively mutate/refine the stochastic model and guides test generation from the mutated models toward achieving high code and model coverage and exhibiting diverse sequences. During testing, system-level events are randomly injected to further enhance the testing effectiveness.  
Stoat was evaluated on 93 open-source apps. The results show (1) the models produced by Stoat cover 17∼31% more code than those by existing modeling tools; (2) Stoat detects 3X more unique crashes than two state-of-the-art testing tools, Monkey and Sapienz. Furthermore, Stoat tested 1661 most popular Google Play apps, and detected 2110 previously unknown and unique crashes. So far, 43 developers have responded that they are investigating our reports. 20 of reported crashes have been confirmed, and 8 already fixed.


### Refining Indirect Call Targets at the Binary Level
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/bpa.pdf)
* **Abstract:** Enforcing fine-grained Control-Flow Integrity (CFI) is critical for increasing software security. However, for commercial off-the-shelf (COTS) binaries, constructing high-precision Control-Flow Graphs (CFGs) is challenging, because there is no source-level information, such as symbols and types, to assist in indirect-branch target inference. The lack of source-level information brings extra challenges to inferring targets for indirect calls compared to other kinds of indirect branches. Points-to analysis could be a promising solution for this problem, but there is no practical points-to analysis framework for inferring indirect call targets at the binary level. Value set analysis (VSA) is the state-of-the-art binary-level points-to analysis but does not scale to large programs. It is also highly conservative by design and thus leads to low-precision CFG construction. In this paper, we present a binary-level points-to analysis framework called BPA to construct sound and high-precision CFGs. It is a new way of performing points-to analysis at the binary level with the focus on resolving indirect call targets. BPA employs several major techniques, including assuming a block memory model and a memory access analysis for partitioning memory into blocks, to achieve a better balance between scalability and precision. In evaluation, we demonstrate that BPA achieves a 34.5% precision improvement rate over the current state-of-the-art technique without introducing false negatives.

### Prospex: Protocol Specification Extraction
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/prospex.pdf)
* **Abstract:** Protocol reverse engineering is the process of extracting
application-level specifications for network protocols. Such specifications are very useful in a number of security-related
contexts, for example, to perform deep packet inspection and black-box fuzzing, or to quickly understand custom botnet
command and control (C&C) channels. Since manual reverse engineering is a time-consuming and tedious process, a number of systems have been proposed that aim to automate this task. These systems either analyze network traffic
directly or monitor the execution of the application that
receives the protocol messages. While previous systems show
that precise message formats can be extracted automatically,
they do not provide a protocol specification. The reason is
that they do not reverse engineer the protocol state machine.  
In this paper, we focus on closing this gap by presenting
a system that is capable of automatically inferring state
machines. This greatly enhances the results of automatic
protocol reverse engineering, while further reducing the
need for human interaction. We extend previous work that
focuses on behavior-based message format extraction, and
introduce techniques for identifying and clustering different
types of messages not only based on their structure, but also
according to the impact of each message on server behavior.
Moreover, we present an algorithm for extracting the state
machine. We have applied our techniques to a number of
real-world protocols, including the command and control
protocol used by a malicious bot. Our results demonstrate
that we are able to extract format specifications for different
types of messages and meaningful protocol state machines.
We use these protocol specifications to automatically generate input for a stateful fuzzer, allowing us to discover
security vulnerabilities in real-world applications.

### Learning deterministic probabilistic automata from a model checking perspective
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/Learning_deterministic_probabilistic_automata_from_a_model_checking_perspective.pdf)
* **Abstract:** Probabilistic automata models play an important role in the formal design and
analysis of hard- and software systems. In this area of applications, one is often interested in
formal model-checking procedures for verifying critical system properties. Since adequate
system models are often difficult to design manually, we are interested in learning models
from observed system behaviors. To this end we adopt techniques for learning finite probabilistic automata, notably the Alergia algorithm. In this paper we show how to extend
the basic algorithm to also learn automata models for both reactive and timed systems. A
key question of our investigation is to what extent one can expect a learned model to be a
good approximation for the kind of probabilistic properties one wants to verify by model
checking. We establish theoretical convergence properties for the learning algorithm as well
as for probability estimates of system properties expressed in linear time temporal logic and
linear continuous stochastic logic. We empirically compare the learning algorithm with statistical model checking and demonstrate the feasibility of the approach for practical system
verification.

### EcoFuzz: Adaptive Energy-Saving Greybox Fuzzing as a Variant of the Adversarial Multi-Armed Bandit
* <img src="../files/images/pdf_24px.png">[Paper](../files/papers/ecofuzz.pdf)
* **Abstract:** Fuzzing is one of the most effective approaches for identifying security vulnerabilities. As a state-of-the-art coverage-based greybox fuzzer, AFL is a highly effective and widely used
technique. However, AFL allocates excessive energy (i.e., the number of test cases generated by the seed) to seeds that exercise the high-frequency paths and can not adaptively adjust the energy allocation, thus wasting a significant amount of energy. Moreover, the current Markov model for modeling coverage-based greybox fuzzing is not profound enough. This paper presents a variant of the Adversarial Multi-Armed Bandit model for modeling AFL’s power schedule process. We first explain the challenges in AFL’s scheduling algorithm by using the reward probability that generates a test case for discovering a new path. Moreover, we illustrated the three states of the seeds set and developed a unique adaptive scheduling algorithm as well as a probability-based search strategy. These approaches are implemented on top of AFL in an adaptive energy-saving greybox fuzzer called EcoFuzz. EcoFuzz is examined against other six AFL-type tools on 14 real-world subjects over 490 CPU days. According to the results, EcoFuzz could attain 214% of the path coverage of AFL with reducing 32% test cases generation of that of AFL. Besides, EcoFuzz identified 12 vulnerabilities in GNU Binutils and other software. We also extended EcoFuzz to test some IoT devices and found a new vulnerability in the SNMP component.

#Researchers
- [ZhenDong Su](https://people.inf.ethz.ch/suz/)
- [Wei Huo](https://people.ucas.ac.cn/~0034331#%20408273)
- [Limin Sun](https://people.ucas.ac.cn/~0002848#%20786254)
- [Le Guan](https://guanle.org/)
- [ShouLing Ji](https://person.zju.edu.cn/sji/698179.html)
- [Chao Zhang](http://netsec.ccert.edu.cn/chs/people/chaoz/)